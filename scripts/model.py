import darknet
import torch.nn as nn
from utils import *
import numpy as np
import torch

"""

https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/
https://github.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch

"""


def letterbox_image(img, inp_dim):
    img_w, img_h = img.shape[1], img.shape[0]
    w, h = inp_dim
    new_w = int(img_w * min(w / img_w, h / img_h))
    new_h = int(img_h * min(w / img_w, h / img_h))
    resized_image = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_CUBIC)

    canvas = np.full((inp_dim[1], inp_dim[0], 3), 128)
    canvas[(h - new_h) // 2:(h - new_h) // 2 + new_h, (w - new_w) // 2:(w - new_w) // 2 + new_w, :] = resized_image

    return canvas, new_h


def prep_image(img, inp_dim):
    img, new_h = (letterbox_image(img, (inp_dim, inp_dim)))
    img = img[:, :, ::-1].transpose((2, 0, 1)).copy()
    img = torch.from_numpy(img).float().div(255.0).unsqueeze(0)

    return img, new_h


class Model(nn.Module):
    def __init__(self, cfgfile):
        super(Model, self).__init__()
        self.blocks = darknet.parse_cfg(cfgfile)
        self.net_info, self.module_list = darknet.create_modules(self.blocks)

    def forward(self, x, CUDA):
        modules = self.blocks[1:]
        outputs = {}

        write = 0
        for i, module in enumerate(modules):
            module_type = (module["type"])

            if module_type == "convolutional" or module_type == "upsample" or module_type == "maxpool":
                x = self.module_list[i](x)

            elif module_type == "route":
                layers = module["layers"]
                layers = [int(a) for a in layers]

                if (layers[0]) > 0:
                    layers[0] = layers[0] - i

                if len(layers) == 1:
                    x = outputs[i + (layers[0])]

                else:
                    if (layers[1]) > 0:
                        layers[1] = layers[1] - i

                    map1 = outputs[i + layers[0]]
                    map2 = outputs[i + layers[1]]
                    x = torch.cat((map1, map2), 1)


            elif module_type == "shortcut":
                from_ = int(module["from"])
                x = outputs[i - 1] + outputs[i + from_]

            elif module_type == 'yolo':
                anchors = self.module_list[i][0].anchors
                inp_dim = int(self.net_info["height"])

                num_classes = int(module["classes"])

                x = x.data

                if CUDA:
                    x = x.cuda()

                x = predict_transform(x, inp_dim, anchors, num_classes, CUDA)
                if not write:
                    detections = x
                    write = 1

                else:
                    detections = torch.cat((detections, x), 1)

            outputs[i] = x

        return detections

    def load_weights(self, weight_path):
        fp = open(weight_path, "rb")

        header = np.fromfile(fp, dtype=np.int32, count=5)
        self.header = torch.from_numpy(header)
        self.seen = self.header[3]

        weights = np.fromfile(fp, dtype=np.float32)

        ptr = 0
        for i in range(len(self.module_list)):
            module_type = self.blocks[i + 1]["type"]

            if module_type == "convolutional":
                model = self.module_list[i]
                try:
                    batch_normalize = int(self.blocks[i + 1]["batch_normalize"])
                except:
                    batch_normalize = 0

                conv = model[0]

                if (batch_normalize):
                    bn = model[1]

                    num_bn_biases = bn.bias.numel()

                    bn_biases = torch.from_numpy(weights[ptr:ptr + num_bn_biases])
                    ptr += num_bn_biases

                    bn_weights = torch.from_numpy(weights[ptr: ptr + num_bn_biases])
                    ptr += num_bn_biases

                    bn_running_mean = torch.from_numpy(weights[ptr: ptr + num_bn_biases])
                    ptr += num_bn_biases

                    bn_running_var = torch.from_numpy(weights[ptr: ptr + num_bn_biases])
                    ptr += num_bn_biases

                    bn_biases = bn_biases.view_as(bn.bias.data)
                    bn_weights = bn_weights.view_as(bn.weight.data)
                    bn_running_mean = bn_running_mean.view_as(bn.running_mean)
                    bn_running_var = bn_running_var.view_as(bn.running_var)

                    bn.bias.data.copy_(bn_biases)
                    bn.weight.data.copy_(bn_weights)
                    bn.running_mean.copy_(bn_running_mean)
                    bn.running_var.copy_(bn_running_var)

                else:
                    num_biases = conv.bias.numel()

                    conv_biases = torch.from_numpy(weights[ptr: ptr + num_biases])
                    ptr = ptr + num_biases

                    conv_biases = conv_biases.view_as(conv.bias.data)

                    conv.bias.data.copy_(conv_biases)

                num_weights = conv.weight.numel()

                conv_weights = torch.from_numpy(weights[ptr:ptr + num_weights])
                ptr = ptr + num_weights

                conv_weights = conv_weights.view_as(conv.weight.data)
                conv.weight.data.copy_(conv_weights)

# if __name__ == "__main__":
#     CUDA = torch.cuda.is_available()
#     model = Model("yolov3-tiny_cups.cfg")
#     model.load_weights("converted.weights")
#     classes = ["cup"]
#     confidence = 0.3
#     nms_thesh = 0.4
#     num_classes = 1
#     inp_dim = int(model.net_info["height"])
#
#     for i in range(6):
#
#         frame = cv2.imread('test_img/{}.png'.format(i + 1))
#
#         img, new_h = prep_image(frame, inp_dim)
#         im_dim = frame.shape[1], frame.shape[0]
#         im_dim = torch.FloatTensor(im_dim).repeat(1, 2)
#         im_dim.cuda()
#
#         if CUDA:
#             im_dim = im_dim.cuda()
#             img = img.cuda()
#             model.cuda()
#
#         start = time.time()
#
#         output = model(img, CUDA)
#         output = write_results(output, confidence, num_classes, nms_conf=nms_thesh)
#
#         output[:, 1:3] = torch.clamp(output[:, 1:3], 0.0, float(inp_dim))
#         output[:, 3:5] = torch.clamp(output[:, 3:5], 0.0, float(348))
#
#         im_dim = im_dim.repeat(output.size(0), 1)
#
#         scaling_factor = torch.min(416 / im_dim, 1)[0].view(-1, 1)
#
#         output[:, [1, 3]] -= (inp_dim - scaling_factor * im_dim[:, 0].view(-1, 1)) / 2
#         output[:, [2, 4]] -= (inp_dim - scaling_factor * im_dim[:, 1].view(-1, 1)) / 2
#
#         output[:, 1:5] /= scaling_factor
#
#         for i in range(output.shape[0]):
#             output[i, [1, 3]] = torch.clamp(output[i, [1, 3]], 0.0, im_dim[i, 0])
#             output[i, [2, 4]] = torch.clamp(output[i, [2, 4]], 0.0, im_dim[i, 1])
#
#         list(map(lambda x: write(x, frame, classes), output))
#
#         print(time.time() - start)
#
#         cv2.imwrite("/home/sayan/Desktop/frame.png", frame)
